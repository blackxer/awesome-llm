# 基础模型

#### 一、预训练
- [ ] [Kimi-VL Technical Report](https://arxiv.org/abs/2504.07491)【2025】
- [ ] [DeepSeek-V3 Technical Report](https://arxiv.org/abs/2412.19437)【2025】
- [ ] [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/abs/2501.12948)【2025】
- [x] TÜLU 3: Pushing Frontiers in Open Language Model Post-Training【[paper](https://allenai.org/papers/tulu-3-report.pdf)】【[code](https://github.com/allenai/open-instruct)】【2024】
- [x] Marco-o1: Towards Open Reasoning Models for Open-Ended Solutions【[paper](https://arxiv.org/abs/2411.14405)】【[code](https://github.com/AIDC-AI/Marco-o1)】【2024】
- [x] ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools【[paper](https://arxiv.org/abs/2406.12793)】【2024】
- [ ] [QwQ](https://qwenlm.github.io/blog/qwq-32b-preview/)【[code](https://modelscope.cn/studios/Qwen/QwQ-32B-preview)】【2024】
- [ ] [Qwen3](https://qwenlm.github.io/blog/qwen3/)【2025】
- [x] [Qwen 2.5](https://arxiv.org/abs/2412.15115)【2024】
- [x] [Qwen 2](https://arxiv.org/pdf/2407.10671)【2024】
- [x] [Qwen 1.5](https://qwenlm.github.io/blog/qwen1.5/)【2024】
- [x] [Qwen 1](https://arxiv.org/pdf/2309.16609)【2023】
- [ ] Gemma 2: Improving Open Language Models at a Practical Size【[paper](https://arxiv.org/abs/2408.00118)】【2024】
- [ ] Gemma: Open Models Based on Gemini Research and Technology【[paper](https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf)】【2024】
- [ ] [2 OLMo 2 Furious](https://arxiv.org/pdf/2501.00656)【2025】
- [ ] [OLMo: Accelerating the Science of Language Models](https://arxiv.org/pdf/2402.00838.pdf)【[code](https://github.com/allenai/OLMo)】【2024】
- [ ] 2x Faster Language Model Pre-training via Masked Structural Growth【[paper](https://arxiv.org/abs/2305.02869)】【2023】
- [ ] Freelm: Fine-tuning-free language model【[paper](https://arxiv.org/abs/2305.01616)】【2023】
- [ ] GPT-4 technical report【[paper](https://arxiv.org/abs/2303.08774)】【2023】
- [ ] Research without Re-search: Maximal Update Parametrization Yields Accurate Loss Prediction across Scales【[paper](https://arxiv.org/abs/2304.06875)】【[code](https://github.com/cofe-ai/Mu-scaling)】【2023】
- [x] FLM-101B: An Open LLM and How to Train It with $100K Budget【[paper](https://arxiv.org/pdf/2309.03852.pdf)】【[code](https://huggingface.co/CofeAI/FLM-101B)】【2023】
- [x] Baichuan2【[paper](https://cdn.baichuan-ai.com/paper/Baichuan2-technical-report.pdf)】【[code](https://github.com/baichuan-inc/Baichuan2)】【2023】
- [ ] llama3 【[论文](https://arxiv.org/abs/2407.21783)】【2024】
- [x] llama2 【[论文](https://arxiv.org/abs/2307.09288)】【[代码](https://github.com/facebookresearch/llama)】【2023】
- [x] llama【[论文](https://arxiv.org/pdf/2302.13971v1.pdf)】【[代码](https://github.com/facebookresearch/llama/tree/llama_v1)】【2023】
- [x] opt 训练日志编年史【[Chronicles ](https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/chronicles/README.md)】【2022】
- [ ] Training Compute-Optimal Large Language Models【[paper](https://arxiv.org/abs/2203.15556)】【2022】
- [ ] Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer【[paper](https://arxiv.org/abs/2203.03466)】【[code](https://github.com/microsoft/mup)】【2022】
- [ ] Scaling Laws for Neural Language Models【[paper](https://arxiv.org/abs/2001.08361)】【2020】
- [ ] Scaling Laws for Autoregressive Generative Modeling【[paper](https://arxiv.org/abs/2010.14701)】【2020】


#### 二、对齐
- [ ] [Reward Hacking in Reinforcement Learning](https://lilianweng.github.io/posts/2024-11-28-reward-hacking/#in-context-reward-hacking)
- [ ] [IOPO: Empowering LLMs with Complex Instruction Following via Input-Output Preference Optimization](https://arxiv.org/abs/2411.06208)【2024】
- [ ] [O1 Replication Journey -- Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesso](https://arxiv.org/abs/2411.16489)【2024】
- [ ] SelfCodeAlign: Self-Alignment for Code Generation【[paper](https://arxiv.org/pdf/2410.24198)】【[code](https://github.com/bigcode-project/selfcodealign)】【2024】
- [ ] [To Believe or Not to Believe Your LLM](https://arxiv.org/abs/2406.02543)【2024】
- [ ] Inverse-RLignment: Inverse Reinforcement Learning from Demonstrations for LLM Alignment【[paper](https://arxiv.org/pdf/2405.15624)】【2024】
- [ ] SimPO: Simple Preference Optimization with a Reference-Free Reward【[paper](https://arxiv.org/pdf/2405.14734)】【[code](https://github.com/princeton-nlp/SimPO)】【2024】
- [ ] [Insights into Alignment:Evaluating DPO and its Variants Across Multiple Tasks](https://arxiv.org/pdf/2404.14723)【2024】
- [ ] Aligner : Achieving Efficient Alignment through Weak-to-Strong Correction【[paper](https://arxiv.org/abs/2402.02416)】【[code](https://aligner2024.github.io)】【2024】
- [ ] A Minimaximalist Approach to Reinforcement Learning from Human Feedback【[paper](https://arxiv.org/abs/2401.04056)】【2024】


#### 三、大模型里的小模型😂
- [ ] [从零训练 Steel-LLM](https://github.com/zhanshijinwat/Steel-LLM/tree/main)【2024】
- [ ] A Comprehensive Survey of Small Language Models in the Era of Large Language Models: Techniques, Enhancements, Applications, Collaboration with LLMs, and Trustworthiness【[paper](https://arxiv.org/abs/2411.03350)】【[code](https://github.com/FairyFali/SLMs-Survey)】【2024】
- [ ] MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases【[paper](https://arxiv.org/pdf/2402.14905.pdf)】【2024】
- [ ] MiniCPM：Unveiling the Potential of End-side Large Language Models【[paper](https://shengdinghu.notion.site/MiniCPM-c805a17c5c8046398914e47f0542095a)】【[code](https://github.com/OpenBMB/MiniCPM)】【2024】
- [ ] SliceGPT: Compress Large Language Models by Deleting Rows and Columns【[paper](https://arxiv.org/pdf/2401.15024.pdf)】【2024】
- [ ] Sheared LLaMA: Accelerating Language Model Pre-training via Structured Pruning【[paper](https://arxiv.org/abs/2310.06694)】【[code](https://xiamengzhou.github.io/sheared-llama/)】【2023】
- [ ] Textbooks Are All You Need II: phi-1.5 technical report【[paper](https://arxiv.org/abs/2309.05463)】【】【2023】
- [ ] TinyLlama-1.1B【[code](https://github.com/jzhang38/TinyLlama)】【2023】


#### 四、位置编码
- [ ] [ROUND AND ROUND WE GO! WHAT MAKES ROTARY POSITIONAL ENCODINGS USEFUL?](https://arxiv.org/pdf/2410.06205)【2024】
- [ ] YaRN: Efficient Context Window Extension of Large Language Models【[paper](https://arxiv.org/abs/2309.00071)】【[code](https://github.com/jquesnelle/yarn)】【2023】
- [ ] A length-extrapolatable transformer【[paper](https://arxiv.org/pdf/2212.10554.pdf)】【[code](https://github.com/sunyt32/torchscale)】【2022】
- [ ] RoFormer: Enhanced Transformer with Rotary Position Embedding【[paper](https://arxiv.org/abs/2104.09864)】【[code](https://github.com/ZhuiyiTechnology/roformer)】【2021】
- [ ] Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation 【[paper](https://arxiv.org/abs/2108.12409)】【[code](https://github.com/ofirpress/attention_with_linear_biases)】【2021】


#### 五、轻量微调
- [ ] Memory Efficient Optimizers with 4-bit States【[paper](https://arxiv.org/abs/2309.01507)】【[code]( https://github.com/thu-ml/low-bit-optimizers)】【2023】
- [x] Stack More Layers Differently:High-Rank Training Through Low-Rank Updates (ReLoRA)【[paper](https://arxiv.org/abs/2307.05695)】【[code](https://github.com/guitaricet/peft_pretraining)】【2023】
- [x] QLORA: Efficient Finetuning of Quantized LLMs 【[论文](https://arxiv.org/pdf/2305.14314v1.pdf)】【[代码](https://github.com/artidoro/qlora)】【2023】
- [x] LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS 【[论文](https://arxiv.org/pdf/2106.09685.pdf)】【[代码](https://github.com/microsoft/LoRA)】【2021】
- [x] INTRINSIC DIMENSIONALITY EXPLAINS THE EFFECTIVENESS OF LANGUAGE MODEL FINE-TUNING 【[论文](https://arxiv.org/pdf/2012.13255.pdf)】【2020】
- [x] MEASURING THE INTRINSIC DIMENSION OF OBJECTIVE LANDSCAPES 【[论文](https://arxiv.org/pdf/1804.08838.pdf)】【2018】


#### 六、提示词工程
- [ ] [Evolving Deeper LLM Thinking](https://arxiv.org/abs/2501.09891)【2025】
- [ ] [From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge](https://arxiv.org/abs/2411.16594)【2024】
- [ ] [Training Large Language Models to Reason in a Continuous Latent Space](https://arxiv.org/pdf/2412.06769)【2024】
- [ ] [Instance-adaptive Zero-shot Chain-of-Thought Prompting](https://arxiv.org/abs/2409.20441)【2024】
- [ ] [The Prompt Report: A Systematic Survey of Prompting Techniques](https://arxiv.org/abs/2406.06608)【2024】
- [ ] [CoX: Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs](https://arxiv.org/abs/2404.15676)【2024】
- [ ] [BoT: Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models](https://arxiv.org/abs/2406.04271)【2024】
- [ ] Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding【[paper](https://arxiv.org/abs/2401.12954)】【[code](https://github.com/suzgunmirac/meta-prompting)】【2024】
- [ ] [PROMPTBREEDER: SELF-REFERENTIAL SELF-IMPROVEMENT VIA PROMPT EVOLUTION](https://arxiv.org/pdf/2309.16797)【2023】
- [ ] Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4【[paper](https://arxiv.org/abs/2312.16171)】【[code](https://github.com/VILA-Lab/ATLAS)】【2023】
- [ ] Towards Better Chain-of-Thought Prompting Strategies: A Survey【[paper](https://browse.arxiv.org/abs/2310.04959)】【2023】
- [ ] Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models (AoT)【[paper](https://arxiv.org/pdf/2308.10379.pdf)】【】【2023】
- [ ] Large Language Models as Optimizers 【[paper](https://arxiv.org/abs/2309.03409)】【2023】
- [ ] Graph of Thoughts: Solving Elaborate Problems with Large Language Models (GoT)【[paper](https://arxiv.org/pdf/2308.09687v2.pdf)】【[code](https://github.com/spcl/graph-of-thoughts)】【2023】
- [x] Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework【[paper](https://arxiv.org/abs/2305.03268)】【[code](https://github.com/RuochenZhao/Verify-and-Edit)】【2023】
- [x] Tree of thoughts: Deliberate problem solving with large language models (ToT)【[paper](https://arxiv.org/pdf/2305.10601.pdf)】【[code](https://github.com/princeton-nlp/tree-of-thought-llm)】【2023】
- [x] Large language model guided tree-of-thought (ToT)【[paper](https://arxiv.org/pdf/2305.08291.pdf)】【[code](https://github.com/jieyilong/tree-of-thought-puzzle-solver)】【2023】
- [x] React: Synergizing reasoning and acting in language models【[paper](https://arxiv.org/abs/2210.03629)】【[code](https://github.com/ysymyth/ReAct)】【2023】
- [x] Reflexion: an autonomous agent with dynamic memory and self-reflection【[paper](https://arxiv.org/pdf/2303.11366.pdf)】【[code](https://github.com/noahshinn024/reflexion)】【2023】
- [ ] Automatic prompt augmentation and selection with chain-of-thought from labeled data【2023】
- [x] Decomposition enhances reasoning via self-evaluation guided decoding【[paper](https://arxiv.org/pdf/2305.00633.pdf)】【[code](https://github.com/YuxiXie/SelfEval-Guided-Decoding)】【2023】
- [x] Self-consistency improves chain of thought reasoning in language models (CoT-SC)【[paper](https://arxiv.org/pdf/2203.11171.pdf)】【2022】
- [x] Chain of thought prompting elicits reasoning in large language models (CoT)【[paper](https://arxiv.org/pdf/2201.11903v6.pdf)】【2022】
- [ ] Automatic Chain of Thought Prompting in Large Language Models【[paper](https://arxiv.org/pdf/2210.03493.pdf)】【2022】
- [ ] LogiCoT: Logical Chain-of-Thought Instruction-Tuning【[paper](https://arxiv.org/pdf/2305.12147.pdf)】【2023】
- [ ] Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models【[paper](https://arxiv.org/pdf/2305.10276.pdf)】【2023】
- [ ] System 2 Attention (is something you might need too)【[paper](https://arxiv.org/pdf/2311.11829.pdf)】【2023】
- [ ] Thread of Thought Unraveling Chaotic Contexts【[paper](https://arxiv.org/abs/2311.08734)】【2023】
- [ ] Tab-CoT: Zero-shot Tabular Chain of Thought【[paper](https://arxiv.org/pdf/2305.17812.pdf)】【2023】
- [ ] Language Models are Few-Shot Learners【[paper](https://arxiv.org/abs/2005.14165v4)】【2020】


#### 七、预训练数据
- [ ] [CCI3.0-HQ 中文数据集](https://arxiv.org/abs/2410.18505)【2024】
- [ ] [A Survey on Data Synthesis and Augmentation for Large Language Models](https://arxiv.org/abs/2410.12896)【2024】


#### 八、指令数据集生成
- [ ] [Scaling Synthetic Data Creation with 1,000,000,000 Personas](https://arxiv.org/pdf/2406.20094);[code](https://github.com/tencent-ailab/persona-hub);2024
- [ ] [Self-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models](https://huggingface.co/papers/2406.13542);[code](https://github.com/QwenLM/AutoIF)【2024】
- [ ] [Best Practices and Lessons Learned on Synthetic Data for Language Models](https://arxiv.org/abs/2404.07503)【2024】
- [ ] Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning【[paper](https://arxiv.org/abs/2402.06619)】【2024】
- [ ] LESS: Selecting Influential Data for Targeted Instruction Tuning【[paper](https://arxiv.org/abs/2402.04333)】【2024】
- [x] Large language models are human-level prompt engineers【[paper](https://arxiv.org/pdf/2211.01910.pdf)】【[code](https://github.com/keirp/automatic_prompt_engineer)】【2023】
- [x] Self-Alignment with Instruction Backtranslation【[paper](https://arxiv.org/abs/2308.06259)】【2023】
- [ ] WizardLM: Empowering Large Language Models to Follow Complex Instructions【[paper](https://arxiv.org/abs/2304.12244)】【2023】
- [ ] LongForm: Optimizing Instruction Tuning for Long Text Generation with Corpus Extraction【[paper](https://arxiv.org/abs/2304.08460)】【2023】
- [ ] Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision【[paper](https://arxiv.org/abs/2305.03047)】【2023】
- [ ] LIMA: Less Is More for Alignment【[paper](https://arxiv.org/abs/2305.11206)】【2023】
- [ ] AlpaGasus: Training A Better Alpaca with Fewer Data【[paper](https://arxiv.org/abs/2307.08701)】【2023】
- [ ] Stanford alpaca: An instruction-following llama model【[code](https://github.com/tatsu-lab/stanford_alpaca#data-generation-process)】【2023】
- [ ] Instruction Tuning with GPT-4【[paper](https://arxiv.org/abs/2304.03277)】【2023】
- [ ] Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality【[paper](https://lmsys.org/blog/2023-03-30-vicuna/)】【2023】
- [ ] Falcon-40B: an open large language model with state-of-the-art performance【[code](https://huggingface.co/tiiuae)】【2023】
- [ ] OpenChat: Advancing Open-source Language Models with Imperfect Data【[code](https://github.com/imoneoi/openchat)】【2023】
- [ ] OpenAssistant Conversations -- Democratizing Large Language Model Alignment【[paper](https://arxiv.org/abs/2304.07327)】【2023】
- [ ] Training language models to follow instructions with human feedback(InstructGPT)【[paper](https://arxiv.org/abs/2203.02155)】【2022】
- [ ] Unnatural Instructions: Tuning Language Models with (Almost) No Human Labor【[paper](https://arxiv.org/abs/2212.09689)】【2022】
- [ ] Self-Instruct: Aligning Language Models with Self-Generated Instructions【[paper](https://arxiv.org/abs/2212.10560)】【2022】


#### 九、Agent
- [ ] [AMOR: A Recipe for Building Adaptable Modular Knowledge Agents Through Process Feedback](https://arxiv.org/abs/2402.01469)【2024】
- [ ] Proactive Agent: Shifting LLM Agents from Reactive Responses to Active Assistance【[paper](https://arxiv.org/abs/2410.12361)】【[code](https://github.com/thunlp/ProactiveAgent)】【2024】
- [ ] AutoManual: Constructing Instruction Manuals by LLM Agents via Interactive Environmental Learning【[paper](https://arxiv.org/abs/2405.16247)】【[code](https://github.com/minghchen/automanual)】【2024】
- [ ] Agents: An Open-source Framework for Autonomous Language Agents【[paper](https://arxiv.org/pdf/2309.07870.pdf)】【[code](https://github.com/aiwaves-cn/agents)】【2023】
- [ ] The Rise and Potential of Large Language Model Based Agents: A Survey【[paper](https://arxiv.org/abs/2309.07864)】【[code](https://github.com/WooooDyy/LLM-Agent-Paper-List)】【2023】
- [ ] ModelScope-Agent: Building Your Customizable Agent System with Open-source Large Language Models【[paper](https://arxiv.org/abs/2309.00986)】【[code](https://github.com/modelscope/modelscope-agent)】【2023】


#### 十、可解释性
- [ ] Explainability for Large Language Models: A Survey【[paper](https://arxiv.org/abs/2309.01029)】【[code](https://github.com/hy-zhao23/Explainability-for-Large-Language-Models)】【2023】
- [ ] Towards Monosemanticity: Decomposing Language Models With Dictionary Learning【[paper](https://transformer-circuits.pub/2023/monosemantic-features/index.html)】【2023】


#### 十一、Embedding
- [ ] [Qwen3 Embedding: Advancing Text Embedding and Reranking Through Foundation Models](https://arxiv.org/abs/2506.05176)【2025】
- [ ] [Piccolo2: General Text Embedding with Multi-task Hybrid Loss Training](https://arxiv.org/abs/2405.06932)【2024】
- [ ] Nomic Embed: Training a Reproducible Long Context Text Embedder【[paper](https://static.nomic.ai/reports/2024_Nomic_Embed_Text_Technical_Report.pdf)】【[code](https://github.com/nomic-ai/contrastors)】【2024】
- [ ] BGE M3-Embedding: Multi-Lingual, Multi-Functionality,Multi-Granularity Text Embeddings Through Self-Knowledge Distillation【[paper](https://arxiv.org/pdf/2402.03216.pdf)】【[code](https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/BGE_M3)】【2024】
- [ ] Improving Text Embeddings with Large Language Models【[paper](https://arxiv.org/pdf/2401.00368.pdf)】【2024】
- [ ] Matryoshka Representation Learning 【[paper](https://arxiv.org/pdf/2205.13147.pdf)】【[code](https://github.com/RAIVNLab/MRL)】【2022】
- [ ] Retrieve Anything To Augment Large Language Models (BGE2)【[paper](https://arxiv.org/pdf/2310.07554.pdf)】【[code](https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/llm_embedder)】【2023】


#### 十二、多模态
- [ ] [Genie 2: A large-scale foundation world model](https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/)【2024】
- [ ] [Stable Diffusion 3: Scaling Rectified Flow Transformers for High-Resolution Image Synthesis](https://stabilityai-public-packages.s3.us-west-2.amazonaws.com/Stable+Diffusion+3+Paper.pdf)【2024】
- [ ] [II-Bench: An Image Implication Understanding Benchmark for Multimodal Large Language Models](https://arxiv.org/abs/2406.05862)【2024】
- [ ] [An Introduction to Vision-Language Modeling](https://arxiv.org/pdf/2405.17247)【2024】
- [ ] World Model on Million-Length Video And Language With RingAttention【[paper](https://arxiv.org/abs/2402.08268)】【[code](https://github.com/LargeWorldModel/LWM)】【2024】
- [ ] Bunny【paper待更新】【[code](https://github.com/BAAI-DCAI/Bunny)】【2024】
- [ ] MoE-LLaVA: Mixture of Experts for Large Vision-Language Models【[paper](https://arxiv.org/abs/2401.15947)】【[code](https://github.com/PKU-YuanGroup/MoE-LLaVA)】【2024】
- [ ] Small Language Model Meets with Reinforced Vision Vocabulary【[paper](https://arxiv.org/abs/2401.12503)】【[code](https://github.com/Ucas-HaoranWei/Vary-toy)】【2024】
- [ ] [DALL·E 3](https://cdn.openai.com/papers/dall-e-3.pdf)【2023】
- [ ] Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision, Language, Audio, and Action【[paper](https://arxiv.org/abs/2312.17172)】【[code](https://github.com/allenai/unified-io-2)】【2023】
- [ ] ImageBind: One Embedding Space To Bind Them All【[paper](http://arxiv.org/pdf/2305.05665.pdf)】【[code](http://github.com/facebookresearch/ImageBind)】【2023】
- [ ] LLaVA: Large Language and Vision Assistant【[paper](https://arxiv.org/abs/2310.03744)】【[code](https://github.com/haotian-liu/LLaVA)】【2023】
- [ ] MiniGPT-5: Interleaved Vision-and-Language Generation via Generative Vokens【[paper](https://browse.arxiv.org/pdf/2310.02239v1.pdf)】【[code](https://github.com/eric-ai-lab/MiniGPT-5)】【2023】
- [ ] Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization【[paper](https://arxiv.org/abs/2309.04669)】【[code](https://github.com/jy0205/LaVIT)】【2023】
- [ ] Learning Transferable Visual Models From Natural Language Supervision (clip)【[paper](https://arxiv.org/abs/2103.00020)】【[code](https://github.com/OpenAI/CLIP)】【2021】
https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models

#### 综述
- [ ] A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications【[paper](https://arxiv.org/abs/2402.07927)】【2024】
- [ ] Large Language Models: A Survey【[paper](https://arxiv.org/pdf/2402.06196.pdf)】【2024】
- [ ] MM-LLMs: Recent Advances in MultiModal Large Language Models【[paper](https://arxiv.org/abs/2401.13601)】【2024】
- [ ] The What, Why, and How of Context Length Extension Techniques in Large Language Models – A Detailed Survey【[paper](https://arxiv.org/pdf/2401.07872.pdf)】【2024】
- [ ] A Survey on Data Augmentation in Large Model Era【[paper](https://export.arxiv.org/abs/2401.15422)】【[code](https://github.com/MLGroup-JLU/LLM-data-aug-survey)】【2024】
- [ ] [A Survey on Multimodal Large Language Models](https://arxiv.org/pdf/2306.13549)【[code](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models)】【2023】
- [ ] A Survey of Large Language Models【[paper](https://arxiv.org/abs/2303.18223)】[code](https://github.com/RUCAIBox/LLMSurvey)】【2023】
- [ ] Examining User-Friendly and Open-Sourced Large GPT Models: A Survey on Language, Multimodal, and Scientific GPT Models【[paper](http://arxiv.org/abs/2308.14149)】【[code](https://github.com/GPT-Alternatives/gpt_alternatives)】【2023】


# 垂直领域

#### Text-to-SQL
- [ ] [RSL-SQL: Robust Schema Linking in Text-to-SQL Generation](https://arxiv.org/abs/2411.00073)

#### 语音识别
- [ ] [Kimi-Audio Technical Report](https://arxiv.org/abs/2504.18425)【2025】
- [ ] [Dolphin: A Large-Scale Automatic Speech Recognition Model for Eastern Languages](https://arxiv.org/abs/2503.20212)【2025】

#### 语音合成
- [ ] [IndexTTS: An Industrial-Level Controllable and Efficient Zero-Shot Text-To-Speech System](https://arxiv.org/abs/2502.05512)【2025】
- [ ] [CosyVoice 3: Towards In-the-wild Speech Generation via Scaling-up and Post-training](https://arxiv.org/abs/2505.17589)【2025】
- [ ] [CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models](https://arxiv.org/abs/2412.10117)【2025】
- [ ] [CosyVoice 1](https://funaudiollm.github.io/pdf/CosyVoice_v1.pdf)【2025】
