# åŸºç¡€æ¨¡å‹

#### ä¸€ã€é¢„è®­ç»ƒ
- [ ] [Kimi-VL Technical Report](https://arxiv.org/abs/2504.07491)ã€2025ã€‘
- [ ] [DeepSeek-V3 Technical Report](https://arxiv.org/abs/2412.19437)ã€2025ã€‘
- [ ] [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/abs/2501.12948)ã€2025ã€‘
- [x] TÃœLU 3: Pushing Frontiers in Open Language Model Post-Trainingã€[paper](https://allenai.org/papers/tulu-3-report.pdf)ã€‘ã€[code](https://github.com/allenai/open-instruct)ã€‘ã€2024ã€‘
- [x] Marco-o1: Towards Open Reasoning Models for Open-Ended Solutionsã€[paper](https://arxiv.org/abs/2411.14405)ã€‘ã€[code](https://github.com/AIDC-AI/Marco-o1)ã€‘ã€2024ã€‘
- [x] ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Toolsã€[paper](https://arxiv.org/abs/2406.12793)ã€‘ã€2024ã€‘
- [ ] [QwQ](https://qwenlm.github.io/blog/qwq-32b-preview/)ã€[code](https://modelscope.cn/studios/Qwen/QwQ-32B-preview)ã€‘ã€2024ã€‘
- [ ] [Qwen3](https://qwenlm.github.io/blog/qwen3/)ã€2025ã€‘
- [x] [Qwen 2.5](https://arxiv.org/abs/2412.15115)ã€2024ã€‘
- [x] [Qwen 2](https://arxiv.org/pdf/2407.10671)ã€2024ã€‘
- [x] [Qwen 1.5](https://qwenlm.github.io/blog/qwen1.5/)ã€2024ã€‘
- [x] [Qwen 1](https://arxiv.org/pdf/2309.16609)ã€2023ã€‘
- [ ] Gemma 2: Improving Open Language Models at a Practical Sizeã€[paper](https://arxiv.org/abs/2408.00118)ã€‘ã€2024ã€‘
- [ ] Gemma: Open Models Based on Gemini Research and Technologyã€[paper](https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf)ã€‘ã€2024ã€‘
- [ ] [2 OLMo 2 Furious](https://arxiv.org/pdf/2501.00656)ã€2025ã€‘
- [ ] [OLMo: Accelerating the Science of Language Models](https://arxiv.org/pdf/2402.00838.pdf)ã€[code](https://github.com/allenai/OLMo)ã€‘ã€2024ã€‘
- [ ] 2x Faster Language Model Pre-training via Masked Structural Growthã€[paper](https://arxiv.org/abs/2305.02869)ã€‘ã€2023ã€‘
- [ ] Freelm: Fine-tuning-free language modelã€[paper](https://arxiv.org/abs/2305.01616)ã€‘ã€2023ã€‘
- [ ] GPT-4 technical reportã€[paper](https://arxiv.org/abs/2303.08774)ã€‘ã€2023ã€‘
- [ ] Research without Re-search: Maximal Update Parametrization Yields Accurate Loss Prediction across Scalesã€[paper](https://arxiv.org/abs/2304.06875)ã€‘ã€[code](https://github.com/cofe-ai/Mu-scaling)ã€‘ã€2023ã€‘
- [x] FLM-101B: An Open LLM and How to Train It with $100K Budgetã€[paper](https://arxiv.org/pdf/2309.03852.pdf)ã€‘ã€[code](https://huggingface.co/CofeAI/FLM-101B)ã€‘ã€2023ã€‘
- [x] Baichuan2ã€[paper](https://cdn.baichuan-ai.com/paper/Baichuan2-technical-report.pdf)ã€‘ã€[code](https://github.com/baichuan-inc/Baichuan2)ã€‘ã€2023ã€‘
- [ ] llama3 ã€[è®ºæ–‡](https://arxiv.org/abs/2407.21783)ã€‘ã€2024ã€‘
- [x] llama2 ã€[è®ºæ–‡](https://arxiv.org/abs/2307.09288)ã€‘ã€[ä»£ç ](https://github.com/facebookresearch/llama)ã€‘ã€2023ã€‘
- [x] llamaã€[è®ºæ–‡](https://arxiv.org/pdf/2302.13971v1.pdf)ã€‘ã€[ä»£ç ](https://github.com/facebookresearch/llama/tree/llama_v1)ã€‘ã€2023ã€‘
- [x] opt è®­ç»ƒæ—¥å¿—ç¼–å¹´å²ã€[Chronicles ](https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/chronicles/README.md)ã€‘ã€2022ã€‘
- [ ] Training Compute-Optimal Large Language Modelsã€[paper](https://arxiv.org/abs/2203.15556)ã€‘ã€2022ã€‘
- [ ] Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transferã€[paper](https://arxiv.org/abs/2203.03466)ã€‘ã€[code](https://github.com/microsoft/mup)ã€‘ã€2022ã€‘
- [ ] Scaling Laws for Neural Language Modelsã€[paper](https://arxiv.org/abs/2001.08361)ã€‘ã€2020ã€‘
- [ ] Scaling Laws for Autoregressive Generative Modelingã€[paper](https://arxiv.org/abs/2010.14701)ã€‘ã€2020ã€‘


#### äºŒã€å¯¹é½
- [ ] [Reward Hacking in Reinforcement Learning](https://lilianweng.github.io/posts/2024-11-28-reward-hacking/#in-context-reward-hacking)
- [ ] [IOPO: Empowering LLMs with Complex Instruction Following via Input-Output Preference Optimization](https://arxiv.org/abs/2411.06208)ã€2024ã€‘
- [ ] [O1 Replication Journey -- Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesso](https://arxiv.org/abs/2411.16489)ã€2024ã€‘
- [ ] SelfCodeAlign: Self-Alignment for Code Generationã€[paper](https://arxiv.org/pdf/2410.24198)ã€‘ã€[code](https://github.com/bigcode-project/selfcodealign)ã€‘ã€2024ã€‘
- [ ] [To Believe or Not to Believe Your LLM](https://arxiv.org/abs/2406.02543)ã€2024ã€‘
- [ ] Inverse-RLignment: Inverse Reinforcement Learning from Demonstrations for LLM Alignmentã€[paper](https://arxiv.org/pdf/2405.15624)ã€‘ã€2024ã€‘
- [ ] SimPO: Simple Preference Optimization with a Reference-Free Rewardã€[paper](https://arxiv.org/pdf/2405.14734)ã€‘ã€[code](https://github.com/princeton-nlp/SimPO)ã€‘ã€2024ã€‘
- [ ] [Insights into Alignment:Evaluating DPO and its Variants Across Multiple Tasks](https://arxiv.org/pdf/2404.14723)ã€2024ã€‘
- [ ] Aligner : Achieving Efficient Alignment through Weak-to-Strong Correctionã€[paper](https://arxiv.org/abs/2402.02416)ã€‘ã€[code](https://aligner2024.github.io)ã€‘ã€2024ã€‘
- [ ] A Minimaximalist Approach to Reinforcement Learning from Human Feedbackã€[paper](https://arxiv.org/abs/2401.04056)ã€‘ã€2024ã€‘


#### ä¸‰ã€å¤§æ¨¡å‹é‡Œçš„å°æ¨¡å‹ğŸ˜‚
- [ ] [ä»é›¶è®­ç»ƒ Steel-LLM](https://github.com/zhanshijinwat/Steel-LLM/tree/main)ã€2024ã€‘
- [ ] A Comprehensive Survey of Small Language Models in the Era of Large Language Models: Techniques, Enhancements, Applications, Collaboration with LLMs, and Trustworthinessã€[paper](https://arxiv.org/abs/2411.03350)ã€‘ã€[code](https://github.com/FairyFali/SLMs-Survey)ã€‘ã€2024ã€‘
- [ ] MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Casesã€[paper](https://arxiv.org/pdf/2402.14905.pdf)ã€‘ã€2024ã€‘
- [ ] MiniCPMï¼šUnveiling the Potential of End-side Large Language Modelsã€[paper](https://shengdinghu.notion.site/MiniCPM-c805a17c5c8046398914e47f0542095a)ã€‘ã€[code](https://github.com/OpenBMB/MiniCPM)ã€‘ã€2024ã€‘
- [ ] SliceGPT: Compress Large Language Models by Deleting Rows and Columnsã€[paper](https://arxiv.org/pdf/2401.15024.pdf)ã€‘ã€2024ã€‘
- [ ] Sheared LLaMA: Accelerating Language Model Pre-training via Structured Pruningã€[paper](https://arxiv.org/abs/2310.06694)ã€‘ã€[code](https://xiamengzhou.github.io/sheared-llama/)ã€‘ã€2023ã€‘
- [ ] Textbooks Are All You Need II: phi-1.5 technical reportã€[paper](https://arxiv.org/abs/2309.05463)ã€‘ã€ã€‘ã€2023ã€‘
- [ ] TinyLlama-1.1Bã€[code](https://github.com/jzhang38/TinyLlama)ã€‘ã€2023ã€‘


#### å››ã€ä½ç½®ç¼–ç 
- [ ] [ROUND AND ROUND WE GO! WHAT MAKES ROTARY POSITIONAL ENCODINGS USEFUL?](https://arxiv.org/pdf/2410.06205)ã€2024ã€‘
- [ ] YaRN: Efficient Context Window Extension of Large Language Modelsã€[paper](https://arxiv.org/abs/2309.00071)ã€‘ã€[code](https://github.com/jquesnelle/yarn)ã€‘ã€2023ã€‘
- [ ] A length-extrapolatable transformerã€[paper](https://arxiv.org/pdf/2212.10554.pdf)ã€‘ã€[code](https://github.com/sunyt32/torchscale)ã€‘ã€2022ã€‘
- [ ] RoFormer: Enhanced Transformer with Rotary Position Embeddingã€[paper](https://arxiv.org/abs/2104.09864)ã€‘ã€[code](https://github.com/ZhuiyiTechnology/roformer)ã€‘ã€2021ã€‘
- [ ] Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation ã€[paper](https://arxiv.org/abs/2108.12409)ã€‘ã€[code](https://github.com/ofirpress/attention_with_linear_biases)ã€‘ã€2021ã€‘


#### äº”ã€è½»é‡å¾®è°ƒ
- [ ] Memory Efficient Optimizers with 4-bit Statesã€[paper](https://arxiv.org/abs/2309.01507)ã€‘ã€[code]( https://github.com/thu-ml/low-bit-optimizers)ã€‘ã€2023ã€‘
- [x] Stack More Layers Differently:High-Rank Training Through Low-Rank Updates (ReLoRA)ã€[paper](https://arxiv.org/abs/2307.05695)ã€‘ã€[code](https://github.com/guitaricet/peft_pretraining)ã€‘ã€2023ã€‘
- [x] QLORA: Efficient Finetuning of Quantized LLMs ã€[è®ºæ–‡](https://arxiv.org/pdf/2305.14314v1.pdf)ã€‘ã€[ä»£ç ](https://github.com/artidoro/qlora)ã€‘ã€2023ã€‘
- [x] LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS ã€[è®ºæ–‡](https://arxiv.org/pdf/2106.09685.pdf)ã€‘ã€[ä»£ç ](https://github.com/microsoft/LoRA)ã€‘ã€2021ã€‘
- [x] INTRINSIC DIMENSIONALITY EXPLAINS THE EFFECTIVENESS OF LANGUAGE MODEL FINE-TUNING ã€[è®ºæ–‡](https://arxiv.org/pdf/2012.13255.pdf)ã€‘ã€2020ã€‘
- [x] MEASURING THE INTRINSIC DIMENSION OF OBJECTIVE LANDSCAPES ã€[è®ºæ–‡](https://arxiv.org/pdf/1804.08838.pdf)ã€‘ã€2018ã€‘


#### å…­ã€æç¤ºè¯å·¥ç¨‹
- [ ] [Evolving Deeper LLM Thinking](https://arxiv.org/abs/2501.09891)ã€2025ã€‘
- [ ] [From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge](https://arxiv.org/abs/2411.16594)ã€2024ã€‘
- [ ] [Training Large Language Models to Reason in a Continuous Latent Space](https://arxiv.org/pdf/2412.06769)ã€2024ã€‘
- [ ] [Instance-adaptive Zero-shot Chain-of-Thought Prompting](https://arxiv.org/abs/2409.20441)ã€2024ã€‘
- [ ] [The Prompt Report: A Systematic Survey of Prompting Techniques](https://arxiv.org/abs/2406.06608)ã€2024ã€‘
- [ ] [CoX: Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs](https://arxiv.org/abs/2404.15676)ã€2024ã€‘
- [ ] [BoT: Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models](https://arxiv.org/abs/2406.04271)ã€2024ã€‘
- [ ] Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffoldingã€[paper](https://arxiv.org/abs/2401.12954)ã€‘ã€[code](https://github.com/suzgunmirac/meta-prompting)ã€‘ã€2024ã€‘
- [ ] [PROMPTBREEDER: SELF-REFERENTIAL SELF-IMPROVEMENT VIA PROMPT EVOLUTION](https://arxiv.org/pdf/2309.16797)ã€2023ã€‘
- [ ] Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4ã€[paper](https://arxiv.org/abs/2312.16171)ã€‘ã€[code](https://github.com/VILA-Lab/ATLAS)ã€‘ã€2023ã€‘
- [ ] Towards Better Chain-of-Thought Prompting Strategies: A Surveyã€[paper](https://browse.arxiv.org/abs/2310.04959)ã€‘ã€2023ã€‘
- [ ] Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models (AoT)ã€[paper](https://arxiv.org/pdf/2308.10379.pdf)ã€‘ã€ã€‘ã€2023ã€‘
- [ ] Large Language Models as Optimizers ã€[paper](https://arxiv.org/abs/2309.03409)ã€‘ã€2023ã€‘
- [ ] Graph of Thoughts: Solving Elaborate Problems with Large Language Models (GoT)ã€[paper](https://arxiv.org/pdf/2308.09687v2.pdf)ã€‘ã€[code](https://github.com/spcl/graph-of-thoughts)ã€‘ã€2023ã€‘
- [x] Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Frameworkã€[paper](https://arxiv.org/abs/2305.03268)ã€‘ã€[code](https://github.com/RuochenZhao/Verify-and-Edit)ã€‘ã€2023ã€‘
- [x] Tree of thoughts: Deliberate problem solving with large language models (ToT)ã€[paper](https://arxiv.org/pdf/2305.10601.pdf)ã€‘ã€[code](https://github.com/princeton-nlp/tree-of-thought-llm)ã€‘ã€2023ã€‘
- [x] Large language model guided tree-of-thought (ToT)ã€[paper](https://arxiv.org/pdf/2305.08291.pdf)ã€‘ã€[code](https://github.com/jieyilong/tree-of-thought-puzzle-solver)ã€‘ã€2023ã€‘
- [x] React: Synergizing reasoning and acting in language modelsã€[paper](https://arxiv.org/abs/2210.03629)ã€‘ã€[code](https://github.com/ysymyth/ReAct)ã€‘ã€2023ã€‘
- [x] Reflexion: an autonomous agent with dynamic memory and self-reflectionã€[paper](https://arxiv.org/pdf/2303.11366.pdf)ã€‘ã€[code](https://github.com/noahshinn024/reflexion)ã€‘ã€2023ã€‘
- [ ] Automatic prompt augmentation and selection with chain-of-thought from labeled dataã€2023ã€‘
- [x] Decomposition enhances reasoning via self-evaluation guided decodingã€[paper](https://arxiv.org/pdf/2305.00633.pdf)ã€‘ã€[code](https://github.com/YuxiXie/SelfEval-Guided-Decoding)ã€‘ã€2023ã€‘
- [x] Self-consistency improves chain of thought reasoning in language models (CoT-SC)ã€[paper](https://arxiv.org/pdf/2203.11171.pdf)ã€‘ã€2022ã€‘
- [x] Chain of thought prompting elicits reasoning in large language models (CoT)ã€[paper](https://arxiv.org/pdf/2201.11903v6.pdf)ã€‘ã€2022ã€‘
- [ ] Automatic Chain of Thought Prompting in Large Language Modelsã€[paper](https://arxiv.org/pdf/2210.03493.pdf)ã€‘ã€2022ã€‘
- [ ] LogiCoT: Logical Chain-of-Thought Instruction-Tuningã€[paper](https://arxiv.org/pdf/2305.12147.pdf)ã€‘ã€2023ã€‘
- [ ] Chain-of-Symbol Prompting Elicits Planning in Large Langauge Modelsã€[paper](https://arxiv.org/pdf/2305.10276.pdf)ã€‘ã€2023ã€‘
- [ ] System 2 Attention (is something you might need too)ã€[paper](https://arxiv.org/pdf/2311.11829.pdf)ã€‘ã€2023ã€‘
- [ ] Thread of Thought Unraveling Chaotic Contextsã€[paper](https://arxiv.org/abs/2311.08734)ã€‘ã€2023ã€‘
- [ ] Tab-CoT: Zero-shot Tabular Chain of Thoughtã€[paper](https://arxiv.org/pdf/2305.17812.pdf)ã€‘ã€2023ã€‘
- [ ] Language Models are Few-Shot Learnersã€[paper](https://arxiv.org/abs/2005.14165v4)ã€‘ã€2020ã€‘


#### ä¸ƒã€é¢„è®­ç»ƒæ•°æ®
- [ ] [CCI3.0-HQ ä¸­æ–‡æ•°æ®é›†](https://arxiv.org/abs/2410.18505)ã€2024ã€‘
- [ ] [A Survey on Data Synthesis and Augmentation for Large Language Models](https://arxiv.org/abs/2410.12896)ã€2024ã€‘


#### å…«ã€æŒ‡ä»¤æ•°æ®é›†ç”Ÿæˆ
- [ ] [Scaling Synthetic Data Creation with 1,000,000,000 Personas](https://arxiv.org/pdf/2406.20094);[code](https://github.com/tencent-ailab/persona-hub);2024
- [ ] [Self-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models](https://huggingface.co/papers/2406.13542);[code](https://github.com/QwenLM/AutoIF)ã€2024ã€‘
- [ ] [Best Practices and Lessons Learned on Synthetic Data for Language Models](https://arxiv.org/abs/2404.07503)ã€2024ã€‘
- [ ] Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuningã€[paper](https://arxiv.org/abs/2402.06619)ã€‘ã€2024ã€‘
- [ ] LESS: Selecting Influential Data for Targeted Instruction Tuningã€[paper](https://arxiv.org/abs/2402.04333)ã€‘ã€2024ã€‘
- [x] Large language models are human-level prompt engineersã€[paper](https://arxiv.org/pdf/2211.01910.pdf)ã€‘ã€[code](https://github.com/keirp/automatic_prompt_engineer)ã€‘ã€2023ã€‘
- [x] Self-Alignment with Instruction Backtranslationã€[paper](https://arxiv.org/abs/2308.06259)ã€‘ã€2023ã€‘
- [ ] WizardLM: Empowering Large Language Models to Follow Complex Instructionsã€[paper](https://arxiv.org/abs/2304.12244)ã€‘ã€2023ã€‘
- [ ] LongForm: Optimizing Instruction Tuning for Long Text Generation with Corpus Extractionã€[paper](https://arxiv.org/abs/2304.08460)ã€‘ã€2023ã€‘
- [ ] Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervisionã€[paper](https://arxiv.org/abs/2305.03047)ã€‘ã€2023ã€‘
- [ ] LIMA: Less Is More for Alignmentã€[paper](https://arxiv.org/abs/2305.11206)ã€‘ã€2023ã€‘
- [ ] AlpaGasus: Training A Better Alpaca with Fewer Dataã€[paper](https://arxiv.org/abs/2307.08701)ã€‘ã€2023ã€‘
- [ ] Stanford alpaca: An instruction-following llama modelã€[code](https://github.com/tatsu-lab/stanford_alpaca#data-generation-process)ã€‘ã€2023ã€‘
- [ ] Instruction Tuning with GPT-4ã€[paper](https://arxiv.org/abs/2304.03277)ã€‘ã€2023ã€‘
- [ ] Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Qualityã€[paper](https://lmsys.org/blog/2023-03-30-vicuna/)ã€‘ã€2023ã€‘
- [ ] Falcon-40B: an open large language model with state-of-the-art performanceã€[code](https://huggingface.co/tiiuae)ã€‘ã€2023ã€‘
- [ ] OpenChat: Advancing Open-source Language Models with Imperfect Dataã€[code](https://github.com/imoneoi/openchat)ã€‘ã€2023ã€‘
- [ ] OpenAssistant Conversations -- Democratizing Large Language Model Alignmentã€[paper](https://arxiv.org/abs/2304.07327)ã€‘ã€2023ã€‘
- [ ] Training language models to follow instructions with human feedback(InstructGPT)ã€[paper](https://arxiv.org/abs/2203.02155)ã€‘ã€2022ã€‘
- [ ] Unnatural Instructions: Tuning Language Models with (Almost) No Human Laborã€[paper](https://arxiv.org/abs/2212.09689)ã€‘ã€2022ã€‘
- [ ] Self-Instruct: Aligning Language Models with Self-Generated Instructionsã€[paper](https://arxiv.org/abs/2212.10560)ã€‘ã€2022ã€‘


#### ä¹ã€Agent
- [ ] [AMOR: A Recipe for Building Adaptable Modular Knowledge Agents Through Process Feedback](https://arxiv.org/abs/2402.01469)ã€2024ã€‘
- [ ] Proactive Agent: Shifting LLM Agents from Reactive Responses to Active Assistanceã€[paper](https://arxiv.org/abs/2410.12361)ã€‘ã€[code](https://github.com/thunlp/ProactiveAgent)ã€‘ã€2024ã€‘
- [ ] AutoManual: Constructing Instruction Manuals by LLM Agents via Interactive Environmental Learningã€[paper](https://arxiv.org/abs/2405.16247)ã€‘ã€[code](https://github.com/minghchen/automanual)ã€‘ã€2024ã€‘
- [ ] Agents: An Open-source Framework for Autonomous Language Agentsã€[paper](https://arxiv.org/pdf/2309.07870.pdf)ã€‘ã€[code](https://github.com/aiwaves-cn/agents)ã€‘ã€2023ã€‘
- [ ] The Rise and Potential of Large Language Model Based Agents: A Surveyã€[paper](https://arxiv.org/abs/2309.07864)ã€‘ã€[code](https://github.com/WooooDyy/LLM-Agent-Paper-List)ã€‘ã€2023ã€‘
- [ ] ModelScope-Agent: Building Your Customizable Agent System with Open-source Large Language Modelsã€[paper](https://arxiv.org/abs/2309.00986)ã€‘ã€[code](https://github.com/modelscope/modelscope-agent)ã€‘ã€2023ã€‘


#### åã€å¯è§£é‡Šæ€§
- [ ] Explainability for Large Language Models: A Surveyã€[paper](https://arxiv.org/abs/2309.01029)ã€‘ã€[code](https://github.com/hy-zhao23/Explainability-for-Large-Language-Models)ã€‘ã€2023ã€‘
- [ ] Towards Monosemanticity: Decomposing Language Models With Dictionary Learningã€[paper](https://transformer-circuits.pub/2023/monosemantic-features/index.html)ã€‘ã€2023ã€‘


#### åä¸€ã€Embedding
- [ ] [Qwen3 Embedding: Advancing Text Embedding and Reranking Through Foundation Models](https://arxiv.org/abs/2506.05176)ã€2025ã€‘
- [ ] [Piccolo2: General Text Embedding with Multi-task Hybrid Loss Training](https://arxiv.org/abs/2405.06932)ã€2024ã€‘
- [ ] Nomic Embed: Training a Reproducible Long Context Text Embedderã€[paper](https://static.nomic.ai/reports/2024_Nomic_Embed_Text_Technical_Report.pdf)ã€‘ã€[code](https://github.com/nomic-ai/contrastors)ã€‘ã€2024ã€‘
- [ ] BGE M3-Embedding: Multi-Lingual, Multi-Functionality,Multi-Granularity Text Embeddings Through Self-Knowledge Distillationã€[paper](https://arxiv.org/pdf/2402.03216.pdf)ã€‘ã€[code](https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/BGE_M3)ã€‘ã€2024ã€‘
- [ ] Improving Text Embeddings with Large Language Modelsã€[paper](https://arxiv.org/pdf/2401.00368.pdf)ã€‘ã€2024ã€‘
- [ ] Matryoshka Representation Learning ã€[paper](https://arxiv.org/pdf/2205.13147.pdf)ã€‘ã€[code](https://github.com/RAIVNLab/MRL)ã€‘ã€2022ã€‘
- [ ] Retrieve Anything To Augment Large Language Models (BGE2)ã€[paper](https://arxiv.org/pdf/2310.07554.pdf)ã€‘ã€[code](https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/llm_embedder)ã€‘ã€2023ã€‘


#### åäºŒã€å¤šæ¨¡æ€
- [ ] [Genie 2: A large-scale foundation world model](https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/)ã€2024ã€‘
- [ ] [Stable Diffusion 3: Scaling Rectified Flow Transformers for High-Resolution Image Synthesis](https://stabilityai-public-packages.s3.us-west-2.amazonaws.com/Stable+Diffusion+3+Paper.pdf)ã€2024ã€‘
- [ ] [II-Bench: An Image Implication Understanding Benchmark for Multimodal Large Language Models](https://arxiv.org/abs/2406.05862)ã€2024ã€‘
- [ ] [An Introduction to Vision-Language Modeling](https://arxiv.org/pdf/2405.17247)ã€2024ã€‘
- [ ] World Model on Million-Length Video And Language With RingAttentionã€[paper](https://arxiv.org/abs/2402.08268)ã€‘ã€[code](https://github.com/LargeWorldModel/LWM)ã€‘ã€2024ã€‘
- [ ] Bunnyã€paperå¾…æ›´æ–°ã€‘ã€[code](https://github.com/BAAI-DCAI/Bunny)ã€‘ã€2024ã€‘
- [ ] MoE-LLaVA: Mixture of Experts for Large Vision-Language Modelsã€[paper](https://arxiv.org/abs/2401.15947)ã€‘ã€[code](https://github.com/PKU-YuanGroup/MoE-LLaVA)ã€‘ã€2024ã€‘
- [ ] Small Language Model Meets with Reinforced Vision Vocabularyã€[paper](https://arxiv.org/abs/2401.12503)ã€‘ã€[code](https://github.com/Ucas-HaoranWei/Vary-toy)ã€‘ã€2024ã€‘
- [ ] [DALLÂ·E 3](https://cdn.openai.com/papers/dall-e-3.pdf)ã€2023ã€‘
- [ ] Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision, Language, Audio, and Actionã€[paper](https://arxiv.org/abs/2312.17172)ã€‘ã€[code](https://github.com/allenai/unified-io-2)ã€‘ã€2023ã€‘
- [ ] ImageBind: One Embedding Space To Bind Them Allã€[paper](http://arxiv.org/pdf/2305.05665.pdf)ã€‘ã€[code](http://github.com/facebookresearch/ImageBind)ã€‘ã€2023ã€‘
- [ ] LLaVA: Large Language and Vision Assistantã€[paper](https://arxiv.org/abs/2310.03744)ã€‘ã€[code](https://github.com/haotian-liu/LLaVA)ã€‘ã€2023ã€‘
- [ ] MiniGPT-5: Interleaved Vision-and-Language Generation via Generative Vokensã€[paper](https://browse.arxiv.org/pdf/2310.02239v1.pdf)ã€‘ã€[code](https://github.com/eric-ai-lab/MiniGPT-5)ã€‘ã€2023ã€‘
- [ ] Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenizationã€[paper](https://arxiv.org/abs/2309.04669)ã€‘ã€[code](https://github.com/jy0205/LaVIT)ã€‘ã€2023ã€‘
- [ ] Learning Transferable Visual Models From Natural Language Supervision (clip)ã€[paper](https://arxiv.org/abs/2103.00020)ã€‘ã€[code](https://github.com/OpenAI/CLIP)ã€‘ã€2021ã€‘
https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models

#### ç»¼è¿°
- [ ] A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applicationsã€[paper](https://arxiv.org/abs/2402.07927)ã€‘ã€2024ã€‘
- [ ] Large Language Models: A Surveyã€[paper](https://arxiv.org/pdf/2402.06196.pdf)ã€‘ã€2024ã€‘
- [ ] MM-LLMs: Recent Advances in MultiModal Large Language Modelsã€[paper](https://arxiv.org/abs/2401.13601)ã€‘ã€2024ã€‘
- [ ] The What, Why, and How of Context Length Extension Techniques in Large Language Models â€“ A Detailed Surveyã€[paper](https://arxiv.org/pdf/2401.07872.pdf)ã€‘ã€2024ã€‘
- [ ] A Survey on Data Augmentation in Large Model Eraã€[paper](https://export.arxiv.org/abs/2401.15422)ã€‘ã€[code](https://github.com/MLGroup-JLU/LLM-data-aug-survey)ã€‘ã€2024ã€‘
- [ ] [A Survey on Multimodal Large Language Models](https://arxiv.org/pdf/2306.13549)ã€[code](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models)ã€‘ã€2023ã€‘
- [ ] A Survey of Large Language Modelsã€[paper](https://arxiv.org/abs/2303.18223)ã€‘[code](https://github.com/RUCAIBox/LLMSurvey)ã€‘ã€2023ã€‘
- [ ] Examining User-Friendly and Open-Sourced Large GPT Models: A Survey on Language, Multimodal, and Scientific GPT Modelsã€[paper](http://arxiv.org/abs/2308.14149)ã€‘ã€[code](https://github.com/GPT-Alternatives/gpt_alternatives)ã€‘ã€2023ã€‘


# å‚ç›´é¢†åŸŸ

#### Text-to-SQL
- [ ] [RSL-SQL: Robust Schema Linking in Text-to-SQL Generation](https://arxiv.org/abs/2411.00073)

#### è¯­éŸ³è¯†åˆ«
- [ ] [Kimi-Audio Technical Report](https://arxiv.org/abs/2504.18425)ã€2025ã€‘
- [ ] [Dolphin: A Large-Scale Automatic Speech Recognition Model for Eastern Languages](https://arxiv.org/abs/2503.20212)ã€2025ã€‘

#### è¯­éŸ³åˆæˆ
- [ ] [IndexTTS: An Industrial-Level Controllable and Efficient Zero-Shot Text-To-Speech System](https://arxiv.org/abs/2502.05512)ã€2025ã€‘
- [ ] [CosyVoice 3: Towards In-the-wild Speech Generation via Scaling-up and Post-training](https://arxiv.org/abs/2505.17589)ã€2025ã€‘
- [ ] [CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models](https://arxiv.org/abs/2412.10117)ã€2025ã€‘
- [ ] [CosyVoice 1](https://funaudiollm.github.io/pdf/CosyVoice_v1.pdf)ã€2025ã€‘
