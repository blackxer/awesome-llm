# 论文资源

#### 大模型训练
- [ ] 2x Faster Language Model Pre-training via Masked Structural Growth【[paper](https://arxiv.org/abs/2305.02869)】【2023】
- [ ] Freelm: Fine-tuning-free language model【[paper](https://arxiv.org/abs/2305.01616)】【2023】
- [ ] GPT-4 technical report【[paper](https://arxiv.org/abs/2303.08774)】【2023】
- [ ] Research without Re-search: Maximal Update Parametrization Yields Accurate Loss Prediction across Scales【[paper](https://arxiv.org/abs/2304.06875)】【[code](https://github.com/
cofe-ai/Mu-scaling)】【2023】
- [x] FLM-101B: An Open LLM and How to Train It with $100K Budget【[paper](https://arxiv.org/pdf/2309.03852.pdf)】【[code](https://huggingface.co/CofeAI/FLM-101B)】【2023】
- [x] Baichuan2【[paper](https://cdn.baichuan-ai.com/paper/Baichuan2-technical-report.pdf)】【[code](https://github.com/baichuan-inc/Baichuan2)】【2023】
- [x] llama2 【[论文](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/)】【[代码](https://github.com/facebookresearch/llama)】【2023】
- [x] llama【[论文](https://arxiv.org/pdf/2302.13971v1.pdf)】【[代码](https://github.com/facebookresearch/llama/tree/llama_v1)】【2023】
- [x] opt 训练日志编年史【[Chronicles ](https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/chronicles/README.md)】【2022】
- [ ] Training Compute-Optimal Large Language Models【[paper](https://arxiv.org/abs/2203.15556)】【2022】
- [ ] Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer【[paper](https://arxiv.org/abs/2203.03466)】【[code](https://github.com/microsoft/mup)】【2022】
- [ ] Scaling Laws for Neural Language Models【[paper](https://arxiv.org/abs/2001.08361)】【2020】
- [ ] Scaling Laws for Autoregressive Generative Modeling【[paper](https://arxiv.org/abs/2010.14701)】【2020】

#### 位置编码
- [ ] A length-extrapolatable transformer【[paper](https://arxiv.org/pdf/2212.10554.pdf)】【[code](https://github.com/sunyt32/torchscale)】【2022】
- [ ] RoFormer: Enhanced Transformer with Rotary Position Embedding【[paper](https://arxiv.org/abs/2104.09864)】【[code](https://github.com/ZhuiyiTechnology/roformer)】【2021】
- [ ] Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation 【[paper](https://arxiv.org/abs/2108.12409)】【[code](https://github.com/ofirpress/attention_with_linear_biases)】【2021】

#### 轻量微调
- [x] Stack More Layers Differently:High-Rank Training Through Low-Rank Updates (ReLoRA)【[paper](https://arxiv.org/abs/2307.05695)】【[code](https://github.com/guitaricet/peft_pretraining)】【2023】
- [x] QLORA: Efficient Finetuning of Quantized LLMs 【[论文](https://arxiv.org/pdf/2305.14314v1.pdf)】【[代码](https://github.com/artidoro/qlora)】【2023】
- [x] LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS 【[论文](https://arxiv.org/pdf/2106.09685.pdf)】【[代码](https://github.com/microsoft/LoRA)】【2021】
- [x] INTRINSIC DIMENSIONALITY EXPLAINS THE EFFECTIVENESS OF LANGUAGE MODEL FINE-TUNING 【[论文](https://arxiv.org/pdf/2012.13255.pdf)】【2020】
- [x] MEASURING THE INTRINSIC DIMENSION OF OBJECTIVE LANDSCAPES 【[论文](https://arxiv.org/pdf/1804.08838.pdf)】【2018】


#### 思维链推理
- [ ] Graph of Thoughts: Solving Elaborate Problems with Large Language Models (GoT)【[paper](https://arxiv.org/pdf/2308.09687v2.pdf)】【[code](https://github.com/spcl/graph-of-thoughts)】【2023】
- [x] Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework【[paper](https://arxiv.org/abs/2305.03268)】【[code](https://github.com/RuochenZhao/Verify-and-Edit)】【2023】
- [x] Tree of thoughts: Deliberate problem solving with large language models (ToT)【[paper](https://arxiv.org/pdf/2305.10601.pdf)】【[code](https://github.com/princeton-nlp/tree-of-thought-llm)】【2023】
- [x] Large language model guided tree-of-thought (ToT)【[paper](https://arxiv.org/pdf/2305.08291.pdf)】【[code](https://github.com/jieyilong/tree-of-thought-puzzle-solver)】【2023】
- [x] React: Synergizing reasoning and acting in language models【[paper](https://arxiv.org/abs/2210.03629)】【[code](https://github.com/ysymyth/ReAct)】【2023】
- [x] Reflexion: an autonomous agent with dynamic memory and self-reflection【[paper](https://arxiv.org/pdf/2303.11366.pdf)】【[code](https://github.com/noahshinn024/reflexion)】【2023】
- [ ] Automatic prompt augmentation and selection with chain-of-thought from labeled data【2023】
- [x] Decomposition enhances reasoning via self-evaluation guided decoding【[paper](https://arxiv.org/pdf/2305.00633.pdf)】【[code](https://github.com/YuxiXie/SelfEval-Guided-Decoding)】【2023】
- [x]  Self-consistency improves chain of thought reasoning in language models (CoT-SC)【[paper](https://arxiv.org/pdf/2203.11171.pdf)】【2022】
- [x] Chain of thought prompting elicits reasoning in large language models (CoT)【[paper](https://arxiv.org/pdf/2201.11903v6.pdf)】【2022】


#### 指令数据集生成
- [x] Large language models are human-level prompt engineers【[paper](https://arxiv.org/pdf/2211.01910.pdf)】【[code](https://github.com/keirp/automatic_prompt_engineer)】【2023】
- [x] Self-Alignment with Instruction Backtranslation【[paper](https://arxiv.org/abs/2308.06259)】【2023】
- [ ] WizardLM: Empowering Large Language Models to Follow Complex Instructions【[paper](https://arxiv.org/abs/2304.12244)】【2023】
- [ ] LongForm: Optimizing Instruction Tuning for Long Text Generation with Corpus Extraction【[paper](https://arxiv.org/abs/2304.08460)】【2023】
- [ ] Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision【[paper](https://arxiv.org/abs/2305.03047)】【2023】
- [ ] LIMA: Less Is More for Alignment【[paper](https://arxiv.org/abs/2305.11206)】【2023】
- [ ] AlpaGasus: Training A Better Alpaca with Fewer Data【[paper](https://arxiv.org/abs/2307.08701)】【2023】
- [ ] Stanford alpaca: An instruction-following llama model【[code](https://github.com/tatsu-lab/stanford_alpaca#data-generation-process)】【2023】
- [ ] Instruction Tuning with GPT-4【[paper](https://arxiv.org/abs/2304.03277)】【2023】
- [ ] Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality【[paper](https://lmsys.org/blog/2023-03-30-vicuna/)】【2023】
- [ ] Falcon-40B: an open large language model with state-of-the-art performance【[code](https://huggingface.co/tiiuae)】【2023】
- [ ] OpenChat: Advancing Open-source Language Models with Imperfect Data【[code](https://github.com/imoneoi/openchat)】【2023】
- [ ] OpenAssistant Conversations -- Democratizing Large Language Model Alignment【[paper](https://arxiv.org/abs/2304.07327)】【2023】
- [ ] Training language models to follow instructions with human feedback(InstructGPT)【[paper](https://arxiv.org/abs/2203.02155)】【2022】
- [ ] Unnatural Instructions: Tuning Language Models with (Almost) No Human Labor【[paper](https://arxiv.org/abs/2212.09689)】【2022】
- [ ] Self-Instruct: Aligning Language Models with Self-Generated Instructions【[paper](https://arxiv.org/abs/2212.10560)】【2022】
